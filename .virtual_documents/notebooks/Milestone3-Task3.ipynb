import numpy as np
import pandas as pd
from joblib import dump, load
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_validate
import matplotlib.pyplot as plt
plt.style.use('ggplot')
plt.rcParams.update({'font.size': 16, 'axes.labelweight': 'bold', 'figure.figsize': (8,6)})
## add any other additional packages that you need. You are free to use any packages for vizualization.
import altair as alt
alt.data_transformers.disable_max_rows()



## Depending on the permissions that you provided to your bucket you might need to provide your aws credentials
## to read from the bucket, if so provide with your credentials and pass as storage_options=aws_credentials
aws_credentials = {"key" : "ASIARS6J4JEAH2ZOBKCD",
                   "secret": "vhJG5S0k783tWBCqOZlkY8NTwaXZl1jMtfq8gGjT",
                   "token": "FwoGZXIvYXdzELj//////////wEaDLBw9pd5Kse5Pi7LiyLCAasr9ifix3bKDd6nf5hHHCxKTYtX7shxFfRM73uJApDrJmPlhXN1bQ1swlqSJjGrGoly7SPQU6tLqwglmKw2TWkV393XzfM1EfqtgZ0KZgbB9JZfLy9CBTAqmClg95t/waunsP2WlwU2ygC3iiBz2/y1d3UhV+67jqnXdkUQIxVy8nN0DOv7u6IErx8VlqzbTynpMODyXeuBTJzLlVWhQtPQ8chuQIIR9aFi+hpKg28x+0mbVd5GskSqiGMxXrKaWIb2KLn+15IGMi3RZQMGZvXQDEO5coHaTAVAtKgf9EtMS2bEfY4PqGi8dVTOfmDpHfmbHfiHg3A="
                  }
                   
#df = pd.read_csv("s3://mds-s3-group18/output/ml_data_SYD.csv", storage_options=aws_credentials, index_col=0, parse_dates=True)
df = pd.read_csv("ml_data_SYD.csv")


df


## Use your ML skills to get from step 1 to step 6


# Drop rows with na
df = df.dropna()


# Split the data into train (80%) and test (20%) portions with random_state=123

train, test = train_test_split(df, test_size=0.2, random_state=123)


# Carry out EDA of your choice on the train split

# Distribution of target label
(alt.Chart(train).mark_bar().encode(
    alt.X('observed_rainfall', bin=alt.Bin(maxbins=10), title='Observed Rainfall (mm)'),
    y='count()'
))


# Observed rainfall over time
train['time'] = pd.to_datetime(train['time'])
(alt.Chart(train).mark_line().encode(
    x='time',
    y='observed_rainfall'
))


# Train ensemble machine learning model using RandomForestRegressor and evaluate with metric of your choice (e.g., RMSE) by considering Observed as the target column
y_train = train['observed_rainfall']
X_train = train.drop(['observed_rainfall', 'time'], axis=1)

m_rf = RandomForestRegressor()
res = cross_validate(m_rf, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')
print(f"CV-train RMSE: {res['test_score'].mean()*-1}")
m_rf.fit(X_train, y_train)


m_rf.fit(X_train, y_train)


# Predict on test dataset
y_test = test['observed_rainfall']
X_test = test.drop(['observed_rainfall', 'time'], axis=1)

test['Ensemble'] = m_rf.predict(X_test)


# Calculate RMSE for all models
test_wide = test.drop(['time', 'observed_rainfall'], axis=1)
test_wide = pd.melt(test_wide, var_name='model', value_name='rainfall')

test_result = {}

for model in test_wide['model'].unique():
    pred = test_wide.query('model == @model')['rainfall']
    test_result[model] = mean_squared_error(y_test, pred, squared=False)


pd.DataFrame([test_result]).T.rename(columns={0: "RMSE"}).sort_values('RMSE')


model = RandomForestRegressor(n_estimators=100, max_depth=5, bootstrap=False)
model.fit(X_train, y_train)


print(f"Train RMSE: {mean_squared_error(y_train, model.predict(X_train), squared=False):.2f}")
print(f" Test RMSE: {mean_squared_error(y_test, model.predict(X_test), squared=False):.2f}")


# ready to deploy
dump(model, "model.joblib")
